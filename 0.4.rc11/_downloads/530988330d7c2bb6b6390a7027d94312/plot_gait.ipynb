{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gait (steps) example\nIn this example, we use DiCoDiLe on an open dataset of gait (steps) IMU\ntime-series to discover patterns in the data. We will then use those to attempt\nto detect steps and compare our findings with the ground truth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Retrieve trial data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from dicodile.data.gait import get_gait_data\n\ntrial = get_gait_data(subject=6, trial=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s have a look at the data for one trial.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "trial.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We get a dictionary whose keys are metadata items, plus a \u2018data\u2019 key that\ncontains a numpy array with the trial time series for each sensor axis, at\n100 Hz resolution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# right foot acceleration (vertical)\nplt.plot(trial['data']['RAV'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s look at a small portion of the series for both feet, overlaid on the\nsame plot.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots()\nax.plot(trial['data']['LAV'][5000:5800],\n        label='left foot vertical acceleration')\nax.plot(trial['data']['RAV'][5000:5800],\n        label='right foot vertical acceleration')\nax.set_xlabel('time (x10ms)')\nax.set_ylabel('acceleration ($m.s^{-2}$)')\nax.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see the alternating left and right foot movements.\n\nIn the rest of this example, we will only use the right foot vertical\nacceleration.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convolutional Dictionary Learning\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let\u2019s use \"dicodile\" as solver_z to learn patterns from the data and\nreconstruct the signal from a sparse representation.\n\nFirst, we initialize a dictionary from parts of the signal:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X = trial['data']['RAV'].to_numpy()\n\n# reshape X to (n_trials, n_channels, n_times)\nX = X.reshape(1, 1, *X.shape)\n\nprint(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the use of reshape to shape the signal as per alphacsc requirements: the\nshape of the signal should be (n_trials, n_channels, n_times). Here, we have\na single-channel time series so it is (1, 1, n_times).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc.init_dict import init_dictionary\n\n# set dictionary size\nn_atoms = 8\n\n# set individual atom (patch) size.\nn_times_atom = 200\n\nD_init = init_dictionary(X,\n                         n_atoms=8,\n                         n_times_atom=200,\n                         rank1=False,\n                         window=True,\n                         D_init='chunk',\n                         random_state=60)\n\nprint(D_init.shape)\n\n\"\"\nfrom alphacsc import BatchCDL\n\ncdl = BatchCDL(\n    # Shape of the dictionary\n    n_atoms,\n    n_times_atom,\n    rank1=False,\n    uv_constraint='auto',\n    # Number of iteration for the alternate minimization and cvg threshold\n    n_iter=3,\n    # number of workers to be used for dicodile\n    n_jobs=4,\n    # solver for the z-step\n    solver_z='dicodile',\n    solver_z_kwargs={'max_iter': 10000},\n    window=True,\n    D_init=D_init,\n    random_state=60)\n\nres = cdl.fit(X)\n\n\"\"\nfrom dicodile.utils.viz import display_dictionaries\n\nD_hat = res._D_hat\n\nfig = display_dictionaries(D_init, D_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Signal reconstruction\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let's reconstruct the original signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc.utils import construct_X_multi\n\nz_hat = res._z_hat\n\nX_hat = construct_X_multi(z_hat, D_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot a small part of the original and reconstructed signals\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig_hat, ax_hat = plt.subplots()\nax_hat.plot(X[0][0][5000:5800],\n            label='right foot vertical acceleration (ORIGINAL)')\nax_hat.plot(X_hat[0][0][5000:5800],\n            label='right foot vertical acceleration (RECONSTRUCTED)')\nax_hat.set_xlabel('time (x10ms)')\nax_hat.set_ylabel('acceleration ($m.s^{-2}$)')\nax_hat.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that our representation is indeed sparse:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.count_nonzero(z_hat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Besides our visual check, a measure of how closely we\u2019re reconstructing the\noriginal signal is the (normalized) cross-correlation. Let\u2019s compute this:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.correlate(X[0][0], X_hat[0][0]) / np.sqrt(\n    np.correlate(X[0][0], X[0][0]) * np.correlate(X_hat[0][0], X_hat[0][0])\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multichannel signals\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "DiCoDiLe works just as well with multi-channel signals. The gait dataset\ncontains 16 signals (8 for each foot), in the rest of this tutorial, we\u2019ll\nuse three of those.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Left foot Vertical acceleration, Y rotation and X acceleration\nchannels = ['LAV', 'LRY', 'LAX']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s look at a small portion of multi-channel data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "colors = plt.rcParams[\"axes.prop_cycle\"]()\nmc_fig, mc_ax = plt.subplots(len(channels), sharex=True)\n\nfor ax, chan in zip(mc_ax, channels):\n    ax.plot(trial['data'][chan][5000:5800],\n            label=chan, color=next(colors)[\"color\"])\nmc_fig.legend(loc=\"upper center\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s put the data in shape for alphacsc: (n_trials, n_channels, n_times)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_mc_subset = trial['data'][channels].to_numpy().T\n\nX_mc_subset = X_mc_subset.reshape(1, *X_mc_subset.shape)\n\nprint(X_mc_subset.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initialize the dictionary (note that the call is identical to the\nsingle-channel version)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "D_init_mc = init_dictionary(\n    X_mc_subset, n_atoms=8, n_times_atom=200, rank1=False,\n    window=True, D_init='chunk', random_state=60\n)\n\nprint(D_init_mc.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And run DiCoDiLe (note that the call is identical to the single-channel\nversion here as well)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc import BatchCDL\n\ncdl = BatchCDL(\n    # Shape of the dictionary\n    n_atoms,\n    n_times_atom,\n    rank1=False,\n    uv_constraint='auto',\n    # Number of iteration for the alternate minimization and cvg threshold\n    n_iter=3,\n    # number of workers to be used for dicodile\n    n_jobs=4,\n    # solver for the z-step\n    solver_z='dicodile',\n    solver_z_kwargs={'max_iter': 10000},\n    window=True,\n    D_init=D_init_mc,\n    random_state=60)\n\nres = cdl.fit(X_mc_subset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Signal reconstruction (multichannel)\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, let\u2019s reconstruct the original signal\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc.utils import construct_X_multi\n\nz_hat_mc = res._z_hat\n\nD_hat_mc = res._D_hat\n\nX_hat_mc = construct_X_multi(z_hat_mc, D_hat_mc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let\u2019s visually compare a small part of the original and reconstructed signal\nalong with the activations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_hat_mc.shape\n\n\"\"\nviz_start_idx = 4000\nviz_end_idx = 5800\nviz_chan = 2\n\nmax_abs = np.max(np.abs(z_hat_mc), axis=-1)\nmax_abs = max_abs.reshape(z_hat_mc.shape[1], 1)\nz_hat_normalized = z_hat_mc / max_abs\n\nfig_hat_mc, ax_hat_mc = plt.subplots(2, figsize=(12, 8))\n\n# plot original and constructed\nax_hat_mc[0].plot(X_mc_subset[0][viz_chan][viz_start_idx:viz_end_idx],\n                  label='ORIGINAL')\nax_hat_mc[0].plot(X_hat_mc[0][viz_chan][viz_start_idx:viz_end_idx],\n                  label='RECONSTRUCTED')\n\nax_hat_mc[0].set_xlabel('time (x10ms)')\nax_hat_mc[0].legend()\n\n# plot activations\nfor idx in range(z_hat_normalized.shape[1]):\n    ax_hat_mc[1].stem(z_hat_normalized[0][idx][viz_start_idx:viz_end_idx],\n                      linefmt=f\"C{idx}-\",\n                      markerfmt=f\"C{idx}o\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}