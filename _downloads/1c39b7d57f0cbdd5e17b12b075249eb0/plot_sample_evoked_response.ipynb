{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Extracting artifact and evoked response atoms from the sample dataset\n\nThis example illustrates how to learn rank-1 [1]_ atoms on the multivariate\nsample dataset from :code:`mne`. We display a selection of atoms, featuring\nheartbeat and eyeblink artifacts, two atoms of evoked responses, and a\nnon-sinusoidal oscillation.\n\n.. [1] Dupr\u00e9 La Tour, T., Moreau, T., Jas, M., & Gramfort, A. (2018).\n    `Multivariate Convolutional Sparse Coding for Electromagnetic Brain Signals\n    <https://arxiv.org/abs/1805.09654v2>`_. Advances in Neural Information\n    Processing Systems (NIPS).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: Thomas Moreau <thomas.moreau@inria.fr>\n#          Mainak Jas <mainak.jas@telecom-paristech.fr>\n#          Tom Dupre La Tour <tom.duprelatour@telecom-paristech.fr>\n#          Alexandre Gramfort <alexandre.gramfort@telecom-paristech.fr>\n#\n# License: BSD (3-clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us first define the parameters of our model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sampling frequency. The signal will be resampled to match this.\nsfreq = 150.\n\n# Define the shape of the dictionary\nn_atoms = 40\nn_times_atom = int(round(sfreq * 1.0))  # 1000. ms\n\n# Regularization parameter which control sparsity\nreg = 0.1\n\n# number of processors for parallel computing\nn_jobs = 5\n\n# To accelerate the run time of this example, we split the signal in n_slits.\n# The number of splits should actually be the smallest possible to avoid\n# introducing border artifacts in the learned atoms and it should be not much\n# larger than n_jobs.\nn_splits = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we define the parameters for multivariate CSC\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc import GreedyCDL\ncdl = GreedyCDL(\n    # Shape of the dictionary\n    n_atoms=n_atoms,\n    n_times_atom=n_times_atom,\n    # Request a rank1 dictionary with unit norm temporal and spatial maps\n    rank1=True,\n    uv_constraint='separate',\n    # apply a temporal window reparametrization\n    window=True,\n    # at the end, refit the activations with fixed support and no reg to unbias\n    unbiased_z_hat=True,\n    # Initialize the dictionary with random chunk from the data\n    D_init='chunk',\n    # rescale the regularization parameter to be a percentage of lambda_max\n    lmbd_max=\"scaled\",\n    reg=reg,\n    # Number of iteration for the alternate minimization and cvg threshold\n    n_iter=100,\n    eps=1e-4,\n    # solver for the z-step\n    solver_z=\"lgcd\",\n    solver_z_kwargs={'tol': 1e-3,\n                     'max_iter': 100000},\n    # solver for the d-step\n    solver_d='alternate_adaptive',\n    solver_d_kwargs={'max_iter': 300},\n    # sort atoms by explained variances\n    sort_atoms=True,\n    # Technical parameters\n    verbose=1,\n    random_state=0,\n    n_jobs=n_jobs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the sample data from MNE-python and select the gradiometer channels.\nThe MNE sample data contains MEG recordings of a subject with visual and\nauditory stimuli. We load the data using utilities from MNE-python as a Raw\nobject and select the gradiometers from the signal.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\nimport mne\nimport numpy as np\n\nprint(\"Loading the data...\", end='', flush=True)\ndata_path = mne.datasets.sample.data_path()\nsubjects_dir = os.path.join(data_path, \"subjects\")\ndata_dir = os.path.join(data_path, 'MEG', 'sample')\nfile_name = os.path.join(data_dir, 'sample_audvis_raw.fif')\nraw = mne.io.read_raw_fif(file_name, preload=True, verbose=False)\nraw.pick_types(meg='grad', eeg=False, eog=False, stim=True)\nprint('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then, we remove the powerline artifacts and high-pass filter to remove the\ndrift which can impact the CSC technique. The signal is also resampled to\n150 Hz to reduce the computationnal burden.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Preprocessing the data...\", end='', flush=True)\nraw.notch_filter(np.arange(60, 181, 60), n_jobs=n_jobs, verbose=False)\nraw.filter(2, None, n_jobs=n_jobs, verbose=False)\nraw = raw.resample(sfreq, npad='auto', n_jobs=n_jobs, verbose=False)\nprint('done')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load the data as an array and split it in chunks to allow parallel processing\nduring the model fit. Each split is considered as independent.\nTo reduce the impact of border artifacts, we use `apply_window=True`\nwhich scales down the border of each split with a tukey window.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc.utils import split_signal\nX = raw.get_data(picks=['meg'])\ninfo = raw.copy().pick_types(meg=True).info  # info of the loaded channels\nX_split = split_signal(X, n_splits=n_splits, apply_window=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the model and learn rank1 atoms\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cdl.fit(X_split)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we call the `transform` method, which returns the sparse codes\nassociated with X, without changing the dictionary learned during the `fit`.\nNote that we transform on the *unsplit* data so that the sparse codes\nreflect the original data and not the windowed data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "z_hat = cdl.transform(X[None, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display a selection of atoms\n\nWe recognize a heartbeat artifact, an eyeblink artifact, two atoms of evoked\nresponses, and a non-sinusoidal oscillation.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n\n# preselected atoms of interest\nplotted_atoms = [0, 1, 2, 6, 4]\n\nn_plots = 3  # number of plots by atom\nn_columns = min(6, len(plotted_atoms))\nsplit = int(np.ceil(len(plotted_atoms) / n_columns))\nfigsize = (4 * n_columns, 3 * n_plots * split)\nfig, axes = plt.subplots(n_plots * split, n_columns, figsize=figsize)\nfor ii, kk in enumerate(plotted_atoms):\n\n    # Select the axes to display the current atom\n    print(\"\\rDisplaying {}-th atom\".format(kk), end='', flush=True)\n    i_row, i_col = ii // n_columns, ii % n_columns\n    it_axes = iter(axes[i_row * n_plots:(i_row + 1) * n_plots, i_col])\n\n    # Select the current atom\n    u_k = cdl.u_hat_[kk]\n    v_k = cdl.v_hat_[kk]\n\n    # Plot the spatial map of the atom using mne topomap\n    ax = next(it_axes)\n    mne.viz.plot_topomap(u_k, info, axes=ax, show=False)\n    ax.set(title=\"Spatial pattern %d\" % (kk, ))\n\n    # Plot the temporal pattern of the atom\n    ax = next(it_axes)\n    t = np.arange(n_times_atom) / sfreq\n    ax.plot(t, v_k)\n    ax.set_xlim(0, n_times_atom / sfreq)\n    ax.set(xlabel='Time (sec)', title=\"Temporal pattern %d\" % kk)\n\n    # Plot the power spectral density (PSD)\n    ax = next(it_axes)\n    psd = np.abs(np.fft.rfft(v_k, n=256)) ** 2\n    frequencies = np.linspace(0, sfreq / 2.0, len(psd))\n    ax.semilogy(frequencies, psd, label='PSD', color='k')\n    ax.set(xlabel='Frequencies (Hz)', title=\"Power spectral density %d\" % kk)\n    ax.grid(True)\n    ax.set_xlim(0, 30)\n    ax.set_ylim(1e-4, 1e2)\n    ax.legend()\nprint(\"\\rDisplayed {} atoms\".format(len(plotted_atoms)).rjust(40))\n\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the evoked reconstructed envelope\n\nThe MNE sample data contains data for auditory (event_id=1 and 2) and\nvisual stimuli (event_id=3 and 4). We extract the events now so that we can\nlater identify the atoms related to different events. Note that the\nconvolutional sparse coding method does not need to know the events for\nlearning atoms.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "event_id = [1, 2, 3, 4]\nevents = mne.find_events(raw, stim_channel='STI 014')\nevents = mne.pick_events(events, include=event_id)\nevents[:, 0] -= raw.first_samp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For each atom (columns), and for each event (rows), we compute the envelope\nof the reconstructed signal, align it with respect to the event onsets, and\ntake the average. For some atoms, the activations are correlated with the\nevents, leading to a large evoked envelope. The gray area corresponds to\nnot statistically significant values, computing with sampling.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from alphacsc.utils.signal import fast_hilbert\nfrom alphacsc.viz.epoch import plot_evoked_surrogates\nfrom alphacsc.utils.convolution import construct_X_multi\n\n# time window around the events. Note that for the sample datasets, the time\n# inter-event is around 0.5s\nt_lim = (-0.1, 0.5)\n\nn_plots = len(event_id)\nn_columns = min(6, len(plotted_atoms))\nsplit = int(np.ceil(len(plotted_atoms) / n_columns))\nfigsize = (4 * n_columns, 3 * n_plots * split)\nfig, axes = plt.subplots(n_plots * split, n_columns, figsize=figsize)\n\nfor ii, kk in enumerate(plotted_atoms):\n\n    # Select the axes to display the current atom\n    print(\"\\rDisplaying {}-th atom envelope\".format(kk), end='', flush=True)\n    i_row, i_col = ii // n_columns, ii % n_columns\n    it_axes = iter(axes[i_row * n_plots:(i_row + 1) * n_plots, i_col])\n\n    # Select the current atom\n    v_k = cdl.v_hat_[kk]\n    v_k_1 = np.r_[[1], v_k][None]\n    z_k = z_hat[:, kk:kk + 1]\n    X_k = construct_X_multi(z_k, v_k_1, n_channels=1)[0, 0]\n\n    # compute the 'envelope' of the reconstructed signal X_k\n    correlation = np.abs(fast_hilbert(X_k))\n\n    # loop over all events IDs\n    for this_event_id in event_id:\n        this_events = events[events[:, 2] == this_event_id]\n        # plotting function\n        ax = next(it_axes)\n        this_info = info.copy()\n        this_info['event_id'] = this_event_id\n        this_info['events'] = events\n        plot_evoked_surrogates(correlation, info=this_info, t_lim=t_lim, ax=ax,\n                               n_jobs=n_jobs, label='event %d' % this_event_id)\n        ax.set(xlabel='Time (sec)', title=\"Evoked envelope %d\" % kk)\nprint(\"\\rDisplayed {} atoms\".format(len(plotted_atoms)).rjust(40))\nfig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display the equivalent dipole for a learned topomap\n\nFinally, let us fit a dipole to one of the atoms. To fit a dipole,\nwe need the following:\n\n* BEM solution: Obtained by running the cortical reconstruction pipeline\n  of Freesurfer and describes the conductivity of different tissues in\n  the head.\n* Trans: An affine transformation matrix needed to bring the data\n  from sensor space to head space. This is usually done by coregistering\n  the fiducials with the MRI.\n* Noise covariance matrix: To whiten the data so that the assumption\n  of Gaussian noise model with identity covariance matrix is satisfied.\n\nWe recommend users to consult the MNE documentation for further information.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "subjects_dir = os.path.join(data_path, 'subjects')\nfname_bem = os.path.join(subjects_dir, 'sample', 'bem',\n                         'sample-5120-bem-sol.fif')\nfname_trans = os.path.join(data_path, 'MEG', 'sample',\n                           'sample_audvis_raw-trans.fif')\nfname_cov = os.path.join(data_path, 'MEG', 'sample', 'sample_audvis-cov.fif')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us construct an evoked object for MNE with the spatial pattern of the\natoms.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "evoked = mne.EvokedArray(cdl.u_hat_.T, info)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit a dipole to each of the atoms.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dip = mne.fit_dipole(evoked, fname_cov, fname_bem, fname_trans,\n                     n_jobs=n_jobs, verbose=False)[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the dipole fit from the 3rd atom, linked to mu-wave and display the\ngoodness of fit.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "atom_dipole_idx = 4\n\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig = plt.figure(figsize=(10, 4))\n\n# Display the dipole fit\nax = fig.add_subplot(1, 3, 1, projection='3d')\ndip.plot_locations(fname_trans, 'sample', subjects_dir, idx=atom_dipole_idx,\n                   ax=ax)\nax.set_title('Atom #{} (GOF {:.2f}%)'.format(atom_dipole_idx,\n                                             dip.gof[atom_dipole_idx]))\n\n# Plot the spatial map\nax = fig.add_subplot(1, 3, 2)\nmne.viz.plot_topomap(cdl.u_hat_[atom_dipole_idx], info, axes=ax)\n\n# Plot the temporal atom\nax = fig.add_subplot(1, 3, 3)\nt = np.arange(n_times_atom) / sfreq\nax.plot(t, cdl.v_hat_[atom_dipole_idx])\nax.set_xlim(0, n_times_atom / sfreq)\nax.set(xlabel='Time (sec)', title=\"Temporal pattern {}\"\n       .format(atom_dipole_idx))\n\nfig.suptitle('')\nfig.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}